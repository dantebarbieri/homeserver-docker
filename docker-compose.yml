secrets:
  EMAIL_PASSWORD:
    file: '${DATA}/dms/secrets/EMAIL_PASSWORD'
  JWT_SECRET:
    file: '${DATA}/authelia/secrets/JWT_SECRET'
  SESSION_SECRET:
    file: '${DATA}/authelia/secrets/SESSION_SECRET'
  STORAGE_PASSWORD:
    file: '${DATA}/authelia/secrets/STORAGE_PASSWORD'
  STORAGE_ENCRYPTION_KEY:
    file: '${DATA}/authelia/secrets/STORAGE_ENCRYPTION_KEY'
services:
  authelia:
    container_name: 'authelia'
    image: 'docker.io/authelia/authelia:latest'
    restart: 'unless-stopped'
    networks:
      - authelia
      - default
    secrets:
      - EMAIL_PASSWORD
      - JWT_SECRET
      - SESSION_SECRET
      - STORAGE_PASSWORD
      - STORAGE_ENCRYPTION_KEY
    environment:
      AUTHELIA_IDENTITY_VALIDATION_RESET_PASSWORD_JWT_SECRET_FILE: '/run/secrets/JWT_SECRET'
      AUTHELIA_SESSION_SECRET_FILE: '/run/secrets/SESSION_SECRET'
      AUTHELIA_STORAGE_POSTGRES_PASSWORD_FILE: '/run/secrets/STORAGE_PASSWORD'
      AUTHELIA_STORAGE_ENCRYPTION_KEY_FILE: '/run/secrets/STORAGE_ENCRYPTION_KEY'
      AUTHELIA_NOTIFIER_SMTP_PASSWORD_FILE: '/run/secrets/EMAIL_PASSWORD'
    volumes:
      - '${DATA}/authelia/config:/config'
  
  authelia_postgres:
    container_name: 'authelia_postgres'
    image: postgres
    restart: unless-stopped
    networks:
      - authelia
    volumes:
      - authelia-storage:/var/lib/postgresql/data
    secrets:
      - STORAGE_PASSWORD
    shm_size: 128mb
    environment:
      POSTGRES_PASSWORD_FILE: /run/secrets/STORAGE_PASSWORD
      POSTGRES_USER: authelia

  authelia_redis:
    container_name: 'authelia_redis'
    image: redis
    restart: unless-stopped
    networks:
      - authelia

  admin.danteb.com:
    build:
      context: .
      dockerfile: Dockerfile.sveltekit
      args:
        APP_NAME: admin.danteb.com
    environment:
      NODE_ENV: production
      PORT: 3000
    networks:
      default:
        aliases:
          - admin-danteb
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

  danteb.com:
    build:
      context: .
      dockerfile: Dockerfile.sveltekit
      args:
        APP_NAME: danteb.com
    environment:
      NODE_ENV: production
      PORT: 3000
    networks:
      default:
        aliases:
          - danteb

  adguardhome:
    image: adguard/adguardhome
    container_name: adguardhome
    restart: unless-stopped
    networks:
      - default
    volumes:
      - ${DATA}/adguardhome/workdir:/opt/adguardhome/work
      - ${DATA}/adguardhome/confdir:/opt/adguardhome/conf
    ports:
      - "53:53/tcp"
      - "53:53/udp"
      - "67:67/udp"
      - "68:68/udp"
      - "443:443/udp"
      - "3000:3000/tcp"
      - "853:853/tcp"
      - "853:853/udp"
      - "5443:5443/tcp"
      - "5443:5443/udp"
      - "6060:6060/tcp"

  homer:
    image: b4bz/homer
    container_name: homer
    user: "${UID}:${GID}"
    environment:
      INIT_ASSETS: 1
    networks:
      - default
    volumes:
      - ${CONFIG}/homeserver/homer/data:/www/assets

  dashdot:
    image: mauricenino/dashdot:nvidia
    container_name: dashdot
    restart: unless-stopped
    privileged: true
    deploy:
      resources:
        reservations:
          devices:
            - capabilities:
                - gpu
    networks:
      - default
    volumes:
      - /:/mnt/host:ro
    environment:
      DASHDOT_WIDGET_LIST: "os,cpu,storage,ram,network,gpu"
      DASHDOT_SHOW_HOST: true
      DASHDOT_ENABLE_CPU_TEMPS: true
      DASHDOT_NETWORK_LABEL_LIST: type,speed_up,speed_down,interface_speed,public_ip
      DASHDOT_ACCEPT_OOKLA_EULA: true
      DASHDOT_USE_NETWORK_INTERFACE: wlp193s0
      DASHDOT_OVERRIDE_OS: Debian 12 (bookworm)
      DASHDOT_OVERRIDE_ARCH: amd64
      DASHDOT_FS_DEVICE_FILTER: nvme1n1,sda,sdb,sdc,sdd,sde,sdf,sdg,sdh,sdi,sdj,sdk,sdl
      DASHDOT_FS_VIRTUAL_MOUNTS: /dev/mapper/vg_redundant-lv_data

  immich-server:
    container_name: immich_server
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    extends:
      file: hwaccel.transcoding.yml
      service: nvenc
    networks:
      - default
      - immich
    volumes:
      - ${UPLOAD_LOCATION}:/usr/src/app/upload
      - /etc/localtime:/etc/localtime:ro
    env_file:
      - .env
    depends_on:
      - redis
      - database
    restart: always
    healthcheck:
      disable: false

  immich-machine-learning:
    container_name: immich_machine_learning
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}-cuda
    extends:
      file: hwaccel.ml.yml
      service: cuda
    networks:
      - immich
    volumes:
      - model-cache:/cache
    env_file:
      - .env
    restart: always
    healthcheck:
      disable: false

  immich-redis:
    container_name: immich_redis
    image: docker.io/redis:6.2-alpine@sha256:2ba50e1ac3a0ea17b736ce9db2b0a9f6f8b85d4c27d5f5accc6a416d8f42c6d5
    networks:
      - immich
    restart: always
    healthcheck:
      test: redis-cli ping || exit 1

  immich-postgres:
    container_name: immich_postgres
    image: docker.io/tensorchord/pgvecto-rs:pg14-v0.2.0@sha256:90724186f0a3517cf6914295b5ab410db9ce23190a2d9d0b9dd6463e3fa298f0
    command:
      [
        "postgres",
        "-c",
        "shared_preload_libraries=vectors.so",
        "-c",
        'search_path="$$user", public, vectors',
        "-c",
        "logging_collector=on",
        "-c",
        "max_wal_size=2GB",
        "-c",
        "shared_buffers=512MB",
        "-c",
        "wal_compression=on",
      ]
    environment:
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_USER: ${DB_USERNAME}
      POSTGRES_DB: ${DB_DATABASE_NAME}
      POSTGRES_INITDB_ARGS: "--data-checksums"
    networks:
      - immich
    volumes:
      - pgdata:/var/lib/postgresql/data
    restart: always
    healthcheck:
      test: pg_isready --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' || exit 1; Chksum="$$(psql --dbname='${DB_DATABASE_NAME}' --username='${DB_USERNAME}' --tuples-only --no-align --command='SELECT COALESCE(SUM(checksum_failures), 0) FROM pg_stat_database')"; echo "checksum failure count is $$Chksum"; [ "$$Chksum" = '0' ] || exit 1
      interval: 5m
      start_interval: 30s
      start_period: 5m

  minecraft-server:
    image: itzg/minecraft-server:java8
    container_name: minecraft-server
    restart: unless-stopped
    tty: true
    stdin_open: true
    ports:
      - "36677:25565"
    environment:
      EULA: true
      MODE: "survival"
      MOTD: "§bHardcore§r Minecraft Server\nRunning Version: §c§o%VERSION%§r."
      DIFFICULTY: "hard"
      HARDCORE: true
      OPS: |
        DanteVB
        ElVonHresvelg
      ICON: "/data/assets/hardcore-logo.png"
      OVERRIDE_ICON: true
      ENABLE_QUERY: true
      ENABLE_COMMAND_BLOCK: true
      VIEW_DISTANCE: 16
      MEMORY: 24G
      USE_AIKAR_FLAGS: true
      ALLOW_FLIGHT: true
      STOP_SERVER_ANNOUNCE_DELAY: 60
      STOP_DURATION: 60
      MAX_TICK_TIME: -1
      LOG_TIMESTAMP: true
      LOG_IPS: true
    networks:
      - default
    volumes:
      - minecraft-server:/data
      - ${CONFIG}/minecraft/assets:/data/assets

  rlcraft-minecraft-server:
    image: itzg/minecraft-server:java8
    container_name: rlcraft-minecraft-server
    restart: unless-stopped
    tty: true
    stdin_open: true
    ports:
      - "36676:25565"
    environment:
      EULA: true
      MODE: "survival"
      MOTD: "§aRL Craft§r server running Minecraft §c§o%VERSION%§r."
      DIFFICULTY: "hard"
      OPS: |
        DanteVB
        Otakeb
        Heruth99
      ICON: "https://media.forgecdn.net/avatars/thumbnails/468/243/64/64/637751369169569212.png"
      OVERRIDE_ICON: true
      ENABLE_QUERY: true
      ENABLE_COMMAND_BLOCK: true
      VIEW_DISTANCE: 16
      MEMORY: 12G
      USE_AIKAR_FLAGS: true
      TYPE: "AUTO_CURSEFORGE"
      CF_API_KEY: ${CF_API_KEY}
      CF_SLUG: rlcraft
    networks:
      - default
    volumes:
      - rlcraft-minecraft-server:/data

  nginxproxymanager:
    image: "jc21/nginx-proxy-manager:latest"
    container_name: nginxproxymanager
    restart: unless-stopped
    ports:
      - "80:80"
      - "81:81"
      - "443:443"
    networks:
      - default
    volumes:
      - ${DATA}/nginxproxymanager/data:/data
      - ${DATA}/nginxproxymanager/letsencrypt:/etc/letsencrypt
      - ${DATA}/nginxproxymanager/snippets:/snippets

  plex:
    container_name: plex
    image: plexinc/pms-docker
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities:
                - gpu
    ports:
      - "32400:32400/tcp"
      - "8324:8324/tcp"
      - "32469:32469/tcp"
      - "1900:1900/udp"
      - "32410:32410/udp"
      - "32412:32412/udp"
      - "32413:32413/udp"
      - "32414:32414/udp"
    environment:
      PLEX_UID: ${UID}
      PLEX_GID: ${GID}
      TZ: ${TZ}
      PLEX_CLAIM: ${PLEX_CLAIM}
      ADVERTISE_IP: ${ADVERTISE_IP}
      LAN_NETWORKS: 192.168.1.0/24,172.16.0.0/16
      NVIDIA_VISIBLE_DEVICES: all
      NVIDIA_DRIVER_CAPABILITIES: compute,video,utility
    networks:
      - default
    volumes:
      - ${DATA}/plex/config:/config
      - /tmp/plex:/transcode
      - ${RAID}/shared/media:/data/media
    devices:
      - "/dev/dri:/dev/dri"
    runtime: "nvidia"

  sabnzbd:
    container_name: sabnzbd
    image: ghcr.io/hotio/sabnzbd:latest
    restart: unless-stopped
    logging:
      driver: json-file
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DATA}/sabnzbd/config:/config
      - ${RAID}/shared/usenet:/data/usenet:rw

  qbittorrent:
    image: lscr.io/linuxserver/qbittorrent:latest
    container_name: qbittorrent
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    volumes:
      - ${DATA}/qbittorrent/config:/config
      - ${RAID}/shared/torrents:/data/torrents
      - ${CONFIG}/homeserver/VueTorrent:/vuetorrent
    ports:
      - 6881:6881
      - 6881:6881/udp
    restart: unless-stopped

  recyclarr:
    container_name: recyclarr
    image: ghcr.io/recyclarr/recyclarr:latest
    restart: unless-stopped
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DATA}/recyclarr/config:/config

  radarr:
    container_name: radarr
    image: ghcr.io/hotio/radarr:latest
    restart: unless-stopped
    logging:
      driver: json-file
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DATA}/radarr/config:/config
      - ${RAID}/shared:/data

  sonarr:
    container_name: sonarr
    image: ghcr.io/hotio/sonarr:latest
    restart: unless-stopped
    logging:
      driver: json-file
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DATA}/sonarr/config:/config
      - ${RAID}/shared:/data

  bazarr:
    container_name: bazarr
    image: ghcr.io/hotio/bazarr:nightly
    restart: unless-stopped
    logging:
      driver: json-file
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    depends_on:
      - whisperasr
    volumes:
      - /etc/localtime:/etc/localtime:ro
      - ${DATA}/bazarr/config:/config
      - ${RAID}/shared/media:/data/media

  whisperasr:
    image: onerahmet/openai-whisper-asr-webservice:latest-gpu
    container_name: whisperasr
    environment:
      ASR_MODEL: turbo
      ASR_ENGINE: openai_whisper
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    restart: unless-stopped
    networks:
      - default

  overseerr:
    image: ghcr.io/hotio/overseerr:latest
    container_name: overseerr
    environment:
      LOG_LEVEL: debug
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
      UMASK: "002"
    networks:
      - default
    volumes:
      - ${DATA}/overseerr/config:/app/config
    restart: unless-stopped

  prowlarr:
    container_name: prowlarr
    image: ghcr.io/hotio/prowlarr:latest
    environment:
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
      UMASK: "002"
    networks:
      - default
    volumes:
      - ${DATA}/prowlarr/config:/config

  flaresolverr:
    image: ghcr.io/flaresolverr/flaresolverr:latest
    container_name: flaresolverr
    environment:
      LOG_LEVEL: ${LOG_LEVEL:-info}
      LOG_HTML: ${LOG_HTML:-false}
      CAPTCHA_SOLVER: ${CAPTCHA_SOLVER:-none}
      PUID: ${UID}
      PGID: ${GID}
      TZ: ${TZ}
    networks:
      - default
    restart: unless-stopped

  vaultwarden:
    image: vaultwarden/server:latest
    container_name: vaultwarden
    networks:
      - default
    volumes:
      - vw-data:/data
    restart: unless-stopped

  searxng_redis:
    container_name: searxng_redis
    image: cgr.dev/chainguard/valkey:latest
    command: --save 30 1 --loglevel warning
    restart: unless-stopped
    networks:
      - searxng
    volumes:
      - valkey-data:/data
    cap_drop:
      - ALL
    cap_add:
      - SETGID
      - SETUID
      - DAC_OVERRIDE
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  searxng:
    container_name: searxng
    image: docker.io/searxng/searxng:latest
    restart: unless-stopped
    networks:
      - default
      - searxng
    volumes:
      - ${DATA}/searxng/config:/etc/searxng:rw
    environment:
      - SEARXNG_BASE_URL=https://${SEARXNG_HOSTNAME:-localhost}/
    cap_drop:
      - ALL
    cap_add:
      - CHOWN
      - SETGID
      - SETUID
    logging:
      driver: "json-file"
      options:
        max-size: "1m"
        max-file: "1"

  ntfy:
    image: binwiederhier/ntfy:latest
    container_name: ntfy
    restart: unless-stopped
    environment:
      - TZ=${TZ}
    volumes:
      - ${DATA}/ntfy/config:/etc/ntfy
      - ${DATA}/ntfy/cache:/var/cache/ntfy
    networks:
      - default

  ollama:
    deploy:
      resources:
        reservations:
          devices:
            - driver: ${OLLAMA_GPU_DRIVER:-nvidia}
              count: ${OLLAMA_GPU_COUNT:-1}
              capabilities:
                - gpu
    networks:
      - open-webui
    volumes:
      - ollama:/root/.ollama
    environment:
      OLLAMA_HOST: 0.0.0.0
    container_name: ollama
    pull_policy: always
    tty: true
    restart: unless-stopped
    image: ollama/ollama:${OLLAMA_DOCKER_TAG:-latest}

  open-webui:
    build:
      context: .
      args:
        OLLAMA_BASE_URL: "/ollama"
      dockerfile: Dockerfile
    image: ghcr.io/open-webui/open-webui:${WEBUI_DOCKER_TAG:-main}
    container_name: open-webui
    networks:
      - open-webui
      - default
    volumes:
      - open-webui:/app/backend/data
    depends_on:
      - ollama
    environment:
      ENABLE_RAG_WEB_SEARCH: True
      OLLAMA_BASE_URL: http://ollama:11434
      RAG_WEB_SEARCH_ENGINE: "searxng"
      RAG_WEB_SEARCH_RESULT_COUNT: 3
      RAG_WEB_SEARCH_CONCURRENT_REQUESTS: 10
      SEARXNG_QUERY_URL: http://searxng:8080/search?q=<query>
    restart: unless-stopped

  ddclient:
    image: lscr.io/linuxserver/ddclient:latest
    container_name: ddclient
    restart: unless-stopped
    environment:
      - PUID=${UID}
      - PGID=${GID}
      - TZ=${TZ}
    volumes:
      - ${DATA}/ddclient/config:/config
    networks:
      - default

  endlessh:
    image: shizunge/endlessh-go
    container_name: endlessh
    restart: unless-stopped
    ports:
      - "22:2222"
    command: ["-logtostderr", "-v=1"]

  ouroboros:
    container_name: ouroboros
    hostname: ouroboros
    image: pyouroboros/ouroboros
    environment:
      CLEANUP: true
      INTERVAL: 300
      LOG_LEVEL: info
      SELF_UPDATE: true
      IGNORE: immich-server immich-microservices immich-machine-learning redis database
      TZ: ${TZ}
    restart: unless-stopped
    networks:
      - default
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock

networks:
  authelia:
  default:
  immich:
  open-webui:
  searxng:

volumes:
  authelia-storage:
  pgdata:
  model-cache:
  minecraft-server:
  rlcraft-minecraft-server:
  ollama:
  open-webui:
  valkey-data:
  vw-data:
